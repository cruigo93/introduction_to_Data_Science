{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите нужные библиотеки:\n",
    "    - pandas, numpy, matplotlib\n",
    "    - pipelines, стандартизацию, линейную регрессию, гребневую и лассо регрессию с sklearn\n",
    "    - загрузит cross validation вариант этих регрессий\n",
    "    - также загрузите standart scaler, пайплайны и polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте магическую комманду в notebook чтобы активировать прорисовку matplotlib графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте стиль matplotlib **'seaborn'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные по оценкам ресторанам из HDF5 файла который вы сохранили вчера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы решаем задачу классификации поэтому мы будем предсказывать колонку Rating Text <br>\n",
    "Стоит иметь ввиду что тут есть ранкинг между значениями - так **Very Good > Good > Average**. <br>\n",
    "Поэтому надо это учесть и преобразовать этот вектор в численный вид так чтобы эта информация сохранилась.\n",
    "Стоить отметить что такой response variable встречается *не часто* и обычно не имеет ранкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте вектор ответов в численную форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем такие колонки как av_rating, Rating color, Rating text,\tVotes, Country, Locality Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['av_rating', 'Rating color', 'Rating text', 'Votes', 'Currency', 'City',\n",
    "              'Country', 'Country Code', 'Locality Verbose', 'Restaurant ID', 'Address'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте one-hot-encoding как на первом дз только после этого преобразйуте матрицу X в sparse матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая размерность у выборки X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Ваш ответ здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим у нас тут проблема curse of dimensionality так как размерность наших фич значительно больше чем количество данных <br>\n",
    "#### <center>  Значит сам бог велел использовать Logit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку на train и test. Поставьте параметр random state 123 и размер тестовой выборки должен быть равен 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем использовать стандартный из коробки Logit regression, но поставьте random state 123. Также не забудьте про стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно было бы узнать  насколько мы улучшаем модель увеличивая нашу выборку. Для этого можно использовать функции learning_curve. Для реализации кросс-валидации будем использовать функцию ShuffleSplit. В обоих случаях закрепим random state на 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    # -- ваш код здесь -- #\n",
    "    #\n",
    "    #\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.4,\n",
    "                     color=\"red\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.4, color=\"green\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"red\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"green\", label=\"CV score\")\n",
    "    \n",
    "    plt.title('Learning Curve')\n",
    "\n",
    "    plt.xlabel(\"Size of sample\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Видно что модель не увеиличивает свой score на обучающей выборке, но с увеличением размера разница между тестом и трейном падает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая это имеет смысл использовать модель с более жесткими регулизаторами, чтобы проверить это предположение можно построить кривую которая будет показывать как зависит значение CV accuracy от коэффициента регулярзации $alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, X, y, cv=None,\n",
    "                        n_jobs=1, param_name= # -- ваш код здесь, \n",
    "                        param_range= # -- ваш код здесь):\n",
    "    # -- ваш код здесь -- #\n",
    "    #\n",
    "    #\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.4,\n",
    "                     color=\"red\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.4, color=\"green\")\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color=\"red\", label=\"Training score\")\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color=\"green\", label=\"CV score\")\n",
    "    \n",
    "    plt.title('Vaidation Curve')\n",
    "\n",
    "    plt.xlabel(\"value of parameter {param_name}\".format(param_name=param_name))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перерисуем learning curve c новым оптимальным значением С и типом регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Серебро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизируйте логит модель по Randomized Grid Search\n",
    "\n",
    "Параметры: Random State 123, n_jobs = -1, max_iter=100, solver='lbfgs', cv = 5\n",
    "\n",
    "Используйте распределение stats.expon со scale 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Золото"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу бинарной классификации отзывов IMDB к фильмам. Имеется обучающая выборка с размеченными отзывами, по 12500 отзывов известно, что они хорошие, еще про 12500 – что они плохие. Здесь уже не так просто сразу приступить к машинному обучению, потому что готовой матрицы $X$ нет  – ее надо приготовить. Можно использовать самый простой подход – мешок слов (\"Bag of words\") или Tfidf преобразование. <br>\n",
    "При таком подходе признаками отзыва будут индикаторы наличия в нем каждого слова из всего корпуса, где корпус – это множество всех отзывов. Идея иллюстрируется картинкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваши возможные шаги - они **не** обязательны, кроме первого и последнего пункта. Если вы придумаете что то лучше чтобы поднять качество прогноза то это ок, ограничений тут нет, главное получите на тестовой выборке accuracy выше 65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Разделите выборку на train и тест, random_state поставьте равным 123 а размер тестовой выборки 20%**\n",
    " - **Составим словарь всех слов с помощью CountVectorizer.**\n",
    " - **Закодируем предложения из текстов обучающей выборки индексами входящих слов. Используем разреженный формат.**\n",
    "\n",
    " - **C помощью grid search выберите лучшую модель на кросс-валидации**\n",
    "\n",
    " - **Обучите логистическую регрессию.**\n",
    "\n",
    " - **ВЫ должны получить долю правильных ответов на тестовой выборке большe 65%**\n",
    "\n",
    " - **Если у вас это получилось то вы решили задачу на золото**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 734 ms, sys: 489 ms, total: 1.22 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_train = load_files(\"../aclImdb/train\")\n",
    "text, y = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Ваш код тут --- **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
